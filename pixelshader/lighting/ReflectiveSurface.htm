<html lang="en">
    <head>
        <title>WebGL/GLSL - Reflective surface (Cook-Torrance specular) Pixel Shader</title>
        <meta charset="utf-8">
        <link rel="stylesheet" type="text/css" href="../../css/styles.css">
    </head>

    <body>
        <div id="container"></div>
    </body>

    <script src="../../js/Three.min.js"></script>
    <script src="../../js/Detector.js"></script>

    <script type="x-shader/x-vertex" id="vertexShader">
        // Vertex Shader code

        void main() {
            gl_Position = vec4(position.xy, 1.0, 1.0);
        }
    </script>

    <script type="x-shader/x-fragment" id="fragmentShader">
        // Fragment Shader code

        uniform vec2 uResolution;
        uniform float uGlobalTime;
        uniform vec4 uMouse;
        uniform sampler2D uTexture0;
        uniform samplerCube uTexture1;

        vec3 lightSpotColor = vec3(1.8, 1.2, 0.9);
        vec3 ambientColor = vec3(0.4, 0.3, 0.2);
        vec3 lightDir = normalize(vec3(6.0, 2.0, 2.0));

        float sphereRadius = 0.8;
        vec3 spherePos = vec3(0.0, sphereRadius, 0.5);
        vec3 planePos = vec3(0.0, 0.08, 0.0);

        float raytracePlane(in vec3 ro, in vec3 rd, float tmin, float tmax) {
            vec3 p = ro - planePos;
            float t = -p.y / rd.y;
            if (t > tmin && t < tmax) {
                return t;
            }
            return -1.0;
        }

        float raytraceSphere(in vec3 ro, in vec3 rd, float tmin, float tmax) {
            vec3 ce = ro - spherePos;
            float b = dot(rd, ce);
            float c = dot(ce, ce) - (sphereRadius * sphereRadius);
            float t = b * b - c;
            if (t > tmin) {
                t = -b - sqrt(t);
                if (t < tmax)
                    return t;
            }
            return -1.0;
        }

        float shadowSphere(in vec3 ro, in vec3 rd) {
            vec3 oc = spherePos - ro;
            float b = dot(oc, rd);
            float sh = 1.0;
            if (b > 0.0) {
                float h = dot(oc, oc) - (b * b) - (sphereRadius * sphereRadius);
                sh = 2.0 * h / b;
            }
            return sh;
        }

        // Lighting is done by Spherical Harmonics:
        // http://en.wikipedia.org/wiki/Spherical_harmonics
        // This is a cheap lighting method presented in 2001 by Ravi Ramamoorthi
        // and Pat Hanrahan: http://graphics.stanford.edu/papers/envmap/
        // There's a C program (prefilter.c) provided to compute spherical harmonic
        // coefficients from light probe images (in the floating point format).
        // I used pvalue tool from Radiance package on my Ubuntu system to convert
        // angular light probe images in HDR format to floating point format with
        // the following command:
        // $ pvalue -df -H -h probe_file.hdr > probe_file.float
        // I then have slightly modified prefilter.c to output values with a factor
        // applied to have coefficients in a correct range, and ran the following
        // command:
        // $ ./prefilter probe_file.float 640
        // You can read too the Orange Book, chapter 12.3 (OpenGL Shading Language
        // by Randi J. Rost), it has been very useful.
        struct SHCoefficients {
            vec3 L00, L1m1, L10, L11, L2m2, L2m1, L20, L21, L22;
        };

        // These constants have been calculated with a light probe from this website:
        // http://www.pauldebevec.com/Probes/
        // The light probe is called "Campus at Sunset" on the website.
        SHCoefficients campus = SHCoefficients(
            vec3(  0.7870665,  0.9379944,  0.9799986 ),
            vec3(  0.4376419,  0.5579443,  0.7024107 ),
            vec3( -0.1020717, -0.1824865, -0.2749662 ),
            vec3(  0.4543814,  0.3750162,  0.1968642 ),
            vec3(  0.1841687,  0.1396696,  0.0491580 ),
            vec3( -0.1417495, -0.2186370, -0.3132702 ),
            vec3( -0.3890121, -0.4033574, -0.3639718 ),
            vec3(  0.0872238,  0.0744587,  0.0353051 ),
            vec3(  0.6662600,  0.6706794,  0.5246173 )
        );

        vec3 diffuseColor(vec3 norm, float scale) {
            SHCoefficients c = campus;
            const float C1 = 0.429043;
            const float C2 = 0.511664;
            const float C3 = 0.743125;
            const float C4 = 0.886227;
            const float C5 = 0.247708;
            return (
                C1 * c.L22 * (norm.x * norm.x - norm.y * norm.y) +
                C3 * c.L20 * norm.z * norm.z +
                C4 * c.L00 -
                C5 * c.L20 +
                2.0 * C1 * c.L2m2 * norm.x * norm.y +
                2.0 * C1 * c.L21  * norm.x * norm.z +
                2.0 * C1 * c.L2m1 * norm.y * norm.z +
                2.0 * C2 * c.L11  * norm.x +
                2.0 * C2 * c.L1m1 * norm.y +
                2.0 * C2 * c.L10  * norm.z
            ) * scale;
        }

        float specular(in vec3 rd, in vec3 norm, in vec3 lightDir, float roughness, float fresnel) {

            float NdotL = dot(norm, lightDir);
            float NdotV = dot(norm, -rd);

            float spe = 0.0;
            if (NdotL > 0.0 && NdotV > 0.0) {

                vec3 h = normalize(-rd + lightDir);

                float NdotH = max(dot(norm, h), 0.0);
                float VdotH = max(dot(-rd, h), 0.000001);
                float LdotH = max(dot(lightDir, h), 0.000001);

                // Beckmann distrib
                float cos2a = NdotH * NdotH;
                float tan2a = (cos2a - 1.0) / cos2a;
                float r = max(roughness, 0.01);
                float r2 = r * r;
                float D = exp(tan2a / r2) / (r2 * cos2a * cos2a);

                // Fresnel term - Schlick approximation
                float F = fresnel + (1.0 - fresnel) * pow(1.0 - VdotH, 5.0);

                // Geometric attenuation term
                float G = min(1.0, (2.0 * NdotH / VdotH) * min(NdotV, NdotL));

                // Cook Torrance
                spe = D * F * G / (4.0 * NdotV * NdotL);
            }

            return spe;
        }

        void main() {
            vec2 p = (-uResolution.xy + 2.0 * gl_FragCoord.xy) / uResolution.y;

            // eye rotation
            vec3 eye = vec3(0.0, 1.0, 2.0);
            vec2 rot = 6.2831 * (vec2(0.6 + uGlobalTime * 0.025, sin(uGlobalTime * 0.1) * 0.06) + vec2(1.0, 0.0) * (uMouse.xy - uResolution.xy * 0.25) / uResolution.x);
            eye.yz = cos(rot.y) * eye.yz + sin(rot.y) * eye.zy * vec2(-1.0, 1.0);
            eye.xz = cos(rot.x) * eye.xz + sin(rot.x) * eye.zx * vec2(1.0, -1.0);

            // origin displacement and view direction
            vec3 ro = eye;
            vec3 ta = vec3(0.0, 1.0, 0.0);

            // build camera matrix, I suggest reading the following for camera to world transformation:
            // http://www.cs.toronto.edu/~jepson/csc2503/readings/Camera.pdf (chapter 6.5)
            vec3 cw = normalize(ta - eye);
            vec3 cu = normalize(cross(vec3(0.0, 1.0, 0.0), cw));
            vec3 cv = normalize(cross(cw, cu));
            mat3 cam = mat3(cu, cv, cw);

            // compute ray direction
            vec3 rd = cam * normalize(vec3(p.xy, 1.0));

            vec3 norm;
            vec3 color = textureCube(uTexture1, rd).xyz;
            float occ = 1.0;

            float tmin = 0.1;
            float tmax = 50.0;

            // raytrace the plane
            float tpla = raytracePlane(ro, rd, tmin, tmax);
            if (tpla > tmin) {
                vec3 ppos = ro + rd * tpla - planePos;
                norm = vec3(0.0, 1.0, 0.0);
                vec3 d = spherePos - ppos;
                float l = length(d);
                occ = 1.0 - (dot(norm, d / l) * (sphereRadius * sphereRadius) / (l * l));
                color = vec3(0.1, 0.15, 0.03) * occ;
            }

            // raytrace the sphere
            float tsph = raytraceSphere(ro, rd, tmin, tmax);
            if (tsph > tmin) {
                vec3 spos = ro + rd * tsph;
                norm = normalize(spos - spherePos);
                occ = 0.5 + 0.5 * norm.y;
                color = vec3(0.3, 0.0, 0.0) * occ;
            }

            // if we hit the plane or the sphere
            if (tpla > tmin || tsph > tmin) {
                float fresnel = 1.0;
                float roughness = 0.025;
                float amb = clamp(0.5 + 0.5 * norm.y, 0.0, 1.0);
                float dif = clamp(dot(lightDir, norm), 0.0, 1.0);
                float spe = specular(rd, norm, lightDir, roughness, fresnel);
                float fre = fresnel * clamp(dot(norm, -rd), 0.0, 1.0);
                float sha = 1.0;
                if (tsph < tmin) {
                    vec3 ppos = ro + rd * tpla - planePos;
                    sha = clamp(shadowSphere(ppos, lightDir), 0.0, 1.0);
                }

                vec3 light = 1.0 * dif * diffuseColor(norm, 2.0); // diffuse
                light *= sha;                            // shadows
                light += 1.0 * amb * ambientColor * occ; // ambient

                vec3 rgb = textureCube(uTexture1, reflect(rd, norm)).xyz * occ;
                color += 1.0 * dif * sha * spe;          // specular
                color += pow(rgb, vec3(5.0)) * fre;

                color *= 1.0 * light;

                // distant fog if we don't hit the sphere
                if (tsph < tmin) {
                    color = mix(color, vec3(0.7, 0.65, 0.6), 1.0 - exp(-0.0025 * tpla * tpla));
                }
            } else {
                // the light spot
                float light = clamp(dot(lightDir, rd), 0.0, 1.0);
                color += pow(light, 200.0) * lightSpotColor;

                color = mix(color, vec3(0.7, 0.65, 0.6), pow(1.0 - rd.y, 8.0));
            }

            // gamma correction
            vec3 gamma = vec3(1.0 / 2.2);
            gl_FragColor = vec4(pow(color, gamma), 1.0);
        }
    </script>

    <script type="text/javascript" id="mainCode">
        var container,
            renderer,
            scene,
            mesh,
            camera,
            leftMouseButtonDown = false,
            clock = new THREE.Clock();

        window.addEventListener('resize', onWindowResize, false);
        window.addEventListener('load', function() {

            var cubeMapImage = new Image();
            cubeMapImage.src = "textures/cube01.png";

            function getCubeMapUrls() {
                // We use the following mapping scheme to reference the tiles in the source image:
                // Full cubemap tiles  xyz positions       Required tile sequence
                // [ 0] [ 4] [ 8]      [  ] [py] [  ]      [ ] [2] [ ]
                // [ 1] [ 5] [ 9]      [nx] [pz] [px]      [1] [4] [0]
                // [ 2] [ 6] [10]      [  ] [ny] [  ]      [ ] [3] [ ]
                // [ 3] [ 7] [11]      [  ] [nz] [  ]      [ ] [5] [ ]

                var cubeFaceIndices = [ 9, 1, 4, 6, 5, 7 ]; // xpos, xneg, ypos, yneg, zpos, zneg

                var cubeMapPieces = [];
                var textureWidth = cubeMapImage.width / 3;
                var textureHeight = cubeMapImage.height / 4;
                for(var x = 0; x < 3; x++) {
                    for(var y = 0; y < 4; y++) {
                        var canvas = document.createElement('canvas');
                        canvas.width  = textureWidth;
                        canvas.height = textureHeight;
                        var context2d = canvas.getContext('2d');
                        if (x == 1 && y == 3) { // flip zneg upside down
                            context2d.translate(textureWidth, textureHeight);
                            context2d.rotate(Math.PI);
                        }
                        context2d.drawImage(cubeMapImage, x * textureWidth, y * textureHeight, textureWidth, textureHeight, 0, 0, canvas.width, canvas.height);

                        cubeMapPieces.push(canvas.toDataURL());
                    }
                }
                var urls = [];
                for (var i = 0; i < 6; i++) { // select the right tiles for the 6 different faces of the cubemap
                    urls.push(cubeMapPieces[cubeFaceIndices[i]]);
                }
                return urls;
            }

            // grab the container from the DOM
            container = document.getElementById("container");

            // create a scene
            scene = new THREE.Scene();

            // create a camera the size of the browser window
            camera = new THREE.PerspectiveCamera(
                90,
                window.innerWidth / window.innerHeight,
                1,
                10000);
            camera.position.z = 200;

            // add the camera to the scene
            scene.add(camera);

            // load texture
            var tex0 = THREE.ImageUtils.loadTexture("textures/tex00.jpg");
            tex0.wrapS = tex0.wrapT = THREE.RepeatWrapping;

            // create a shader material
            material = new THREE.ShaderMaterial({
                uniforms: {
                    uResolution: { type:"v2", value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                    uGlobalTime: { type:"f", value: 1.0 },
                    uMouse: { type:"v4", value: new THREE.Vector4(0, 0, 0, 0) },
                    uTexture0: { type:"t", value: tex0 },
                    uTexture1: { type: "t", value: THREE.ImageUtils.loadTextureCube(getCubeMapUrls()) }
                },
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent,
                depthTest: false
            });

            // create a plane mesh and assign the material, then add the mesh to the scene (fullscreen quad)
            mesh = new THREE.Mesh(
                new THREE.PlaneBufferGeometry(2, 2),
                material
            );
            scene.add(mesh);

            // create the renderer and attach it to the DOM
            if (Detector.webgl)
                renderer = new THREE.WebGLRenderer({
                    alpha: true,
                    antialias:true
                });
            else
                renderer = new THREE.CanvasRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);

            container.appendChild(renderer.domElement);

            document.addEventListener('mousedown', onMouseDown, false);
            document.addEventListener('mouseup', onMouseUp, false);
            document.addEventListener('mousemove', onMouseMove, false);

            render();
        });

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            material.uniforms["uResolution"].value = new THREE.Vector2(window.innerWidth, window.innerHeight);
        }

        function onMouseDown(e) {
            if (e.button === 0) {
                leftMouseButtonDown = true;
            }
            var vec4Mouse = material.uniforms["uMouse"].value;
            vec4Mouse.z = e.clientX;
            vec4Mouse.w = e.clientY;
        }

        function onMouseUp(e) {
            if (e.button === 0) {
                leftMouseButtonDown = false;
            } else {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.z = 0.0;
                vec4Mouse.w = 0.0;
            }
        }

        function onMouseMove(e) {
            if (leftMouseButtonDown === true) {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.x = e.clientX;
                vec4Mouse.y = e.clientY;
            }
        }

        function render() {
            material.uniforms["uGlobalTime"].value = clock.getElapsedTime();

            renderer.render(scene, camera);
            requestAnimationFrame(render);
        }
    </script>

</html>
