<html lang="en">
    <head>
        <title>WebGL/GLSL - Spherical Harmonics Pixel Shader</title>
        <meta charset="utf-8">
        <link rel="stylesheet" type="text/css" href="../../css/styles.css">
    </head>

    <body>
        <div id="container"></div>
    </body>

    <script src="../../js/Three.min.js"></script>
    <script src="../../js/Detector.js"></script>

    <script type="x-shader/x-vertex" id="vertexShader">
        // Vertex Shader code

        void main() {
            gl_Position = vec4(position.xy, 1.0, 1.0);
        }
    </script>

    <script type="x-shader/x-fragment" id="fragmentShader">
        // Fragment Shader code

        uniform vec2 uResolution;
        uniform float uGlobalTime;
        uniform vec4 uMouse;

        vec3 ambientColor = vec3(0.2, 0.2, 0.25);
        vec3 specularColor = vec3(1.0, 1.0, 1.0);
        vec3 spotColor = vec3(1.0, 1.0, 1.0);
        vec3 lightDir = normalize(vec3(0.0, 3.0, 5.0));
        vec3 spherePos = vec3(0.0, 1.0, 0.0);

        float raytraceSphere(in vec3 ro, in vec3 rd, float tmin, float tmax, float r) {
            vec3 ce = ro - spherePos;
            float b = dot(rd, ce);
            float c = dot(ce, ce) - r * r;
            float t = b * b - c;
            if (t > tmin) {
                t = -b - sqrt(t);
                if (t < tmax)
                    return t;
            }
            return -1.0;
        }

        // Lighting is done by Spherical Harmonics:
        // http://en.wikipedia.org/wiki/Spherical_harmonics
        // This is a cheap lighting method presented in 2001 by Ravi Ramamoorthi
        // and Pat Hanrahan: http://graphics.stanford.edu/papers/envmap/
        // There's a C program (prefilter.c) provided to compute spherical harmonic
        // coefficients from light probe images (in the floating point format).
        // I used pvalue tool from Radiance package on my Ubuntu system to convert
        // angular light probe images in HDR format to floating point format with
        // the following command:
        // $ pvalue -df -H -h probe_file.hdr > probe_file.float
        // I then have slightly modified prefilter.c to output values with a factor
        // applied to have coefficients in a correct range, and ran the following
        // command:
        // $ ./prefilter probe_file.float 1800
        // You can read too the Orange Book, chapter 12.3 (OpenGL Shading Language
        // by Randi J. Rost), it has been very useful.
        struct SHCoefficients {
            vec3 L00, L1m1, L10, L11, L2m2, L2m1, L20, L21, L22;
        };

        // These constants have been calculated with a light probe from this website:
        // http://www.unparent.com/photos_probes.html
        // The light probe is called "outside my apartment" on the website.
        SHCoefficients outside = SHCoefficients(
            vec3(  0.7038698,  0.8078909,  1.0664997 ),
            vec3(  0.4541330,  0.5645211,  0.8553988 ),
            vec3(  0.2943725,  0.3295115,  0.4464577 ),
            vec3(  0.4771259,  0.5128749,  0.5787071 ),
            vec3(  0.5752824,  0.6244893,  0.7150115 ),
            vec3(  0.1313621,  0.2124211,  0.4307492 ),
            vec3( -0.3124286, -0.3476581, -0.4390439 ),
            vec3(  0.1886868,  0.2103416,  0.2551100 ),
            vec3(  0.0868131,  0.0724930,  0.0100443 )
        );

        vec3 diffuseColor(vec3 norm, float scale) {
            SHCoefficients c = outside;
            const float C1 = 0.429043;
            const float C2 = 0.511664;
            const float C3 = 0.743125;
            const float C4 = 0.886227;
            const float C5 = 0.247708;
            return (
                C1 * c.L22 * (norm.x * norm.x - norm.y * norm.y) +
                C3 * c.L20 * norm.z * norm.z +
                C4 * c.L00 -
                C5 * c.L20 +
                2.0 * C1 * c.L2m2 * norm.x * norm.y +
                2.0 * C1 * c.L21  * norm.x * norm.z +
                2.0 * C1 * c.L2m1 * norm.y * norm.z +
                2.0 * C2 * c.L11  * norm.x +
                2.0 * C2 * c.L1m1 * norm.y +
                2.0 * C2 * c.L10  * norm.z
            ) * scale;
        }

        void main() {
            vec2 p = (-uResolution.xy + 2.0 * gl_FragCoord.xy) / uResolution.y;

            // eye rotation
            vec3 eye = vec3(0.0, 1.0, 4.0);
            vec2 rot = 6.2831 * (vec2(0.1 + uGlobalTime * 0.25, sin(uGlobalTime * 0.5) * 0.06) + vec2(1.0, 0.0) * (uMouse.xy - uResolution.xy * 0.25) / uResolution.x);
            eye.yz = cos(rot.y) * eye.yz + sin(rot.y) * eye.zy * vec2(-1.0, 1.0);
            eye.xz = cos(rot.x) * eye.xz + sin(rot.x) * eye.zx * vec2(1.0, -1.0);

            // origin displacement and view direction
            vec3 ro = eye;
            vec3 ta = vec3(0.0, 1.0, 0.0);

            // build camera matrix, I suggest reading the following for camera to world transformation:
            // http://www.cs.toronto.edu/~jepson/csc2503/readings/Camera.pdf (chapter 6.5)
            vec3 cw = normalize(ta - eye);
            vec3 cu = normalize(cross(vec3(0.0, 1.0, 0.0), cw));
            vec3 cv = normalize(cross(cw, cu));
            mat3 cam = mat3(cu, cv, cw);

            // compute ray direction
            vec3 rd = cam * normalize(vec3(p.xy, 1.0));

            // background
            vec3 color = vec3(0.0);

            float tmin = 0.1;
            float tmax = 50.0;
            // raytrace the sphere
            float t = raytraceSphere(ro, rd, tmin, tmax, 1.0);
            if (t > tmin && t < tmax) {
                vec3 pos = ro + rd * t;
                vec3 norm = normalize(pos - spherePos);
                float occ = 0.5 + 0.5 * norm.y;

                float amb = clamp(0.5 + 0.5 * norm.y, 0.0, 1.0);
                float dif = clamp(dot(lightDir, norm), 0.0, 1.0);

                // Cook Torrance model: http://en.wikipedia.org/wiki/Specular_highlight
                // http://ruh.li/GraphicsCookTorrance.html
                float roughness = 0.05;
                float fresnel = 1.0;

                float NdotL = dot(norm, lightDir);
                float NdotV = dot(norm, -rd);

                float spe = 0.0;
                if (NdotL > 0.0 && NdotV > 0.0) {

                    vec3 h = normalize(-rd + lightDir);

                    float NdotH = max(dot(norm, h), 0.0);
                    float VdotH = max(dot(-rd, h), 0.000001);
                    float LdotH = max(dot(lightDir, h), 0.000001);

                    // Beckmann distribution (microfacet distribution function)
                    float cos2a = NdotH * NdotH;
                    float tan2a = (cos2a - 1.0) / cos2a;
                    float r = max(roughness, 0.01);
                    float r2 = r * r;
                    float D = exp(tan2a / r2) / (r2 * cos2a * cos2a);

                    // Fresnel term - Schlick approximation
                    float F = fresnel + (1.0 - fresnel) * pow(1.0 - VdotH, 5.0);

                    // Geometric attenuation term
                    float g = 2.0 * NdotH / VdotH;
                    float G = min(1.0, g * min(NdotV, NdotL));

                    // Cook Torrance
                    spe = D * F * G / (4.0 * NdotV * NdotL);
                }

                color = amb * ambientColor * occ;
                color += dif * diffuseColor(norm, 0.5) * occ;
                color += dif * spe * specularColor * occ;
            } else {
                // colorize the light spot
                float light = clamp(dot(lightDir, rd), 0.0, 1.0);
                color = 25.0 * pow(light, 1000.0) * spotColor;
            }

            // gamma correction
            vec3 gamma = vec3(1.0 / 2.2);
            gl_FragColor = vec4(pow(color, gamma), 1.0);
        }
    </script>

    <script type="text/javascript" id="mainCode">
        var container,
            renderer,
            scene,
            mesh,
            camera,
            leftMouseButtonDown = false,
            clock = new THREE.Clock();

        window.addEventListener('resize', onWindowResize, false);
        window.addEventListener('load', function() {

            // grab the container from the DOM
            container = document.getElementById("container");

            // create a scene
            scene = new THREE.Scene();

            // create a camera the size of the browser window
            camera = new THREE.PerspectiveCamera(
                90,
                window.innerWidth / window.innerHeight,
                1,
                10000);
            camera.position.z = 200;

            // add the camera to the scene
            scene.add(camera);

            // create a shader material
            material = new THREE.ShaderMaterial({
                uniforms: {
                    uResolution: { type:"v2", value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                    uGlobalTime: { type:"f", value: 1.0 },
                    uMouse: { type:"v4", value: new THREE.Vector4(0, 0, 0, 0) }
                },
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent,
                depthTest: false
            });

            // create a plane mesh and assign the material, then add the mesh to the scene (fullscreen quad)
            mesh = new THREE.Mesh(
                new THREE.PlaneBufferGeometry(2, 2),
                material
            );
            scene.add(mesh);

            // create the renderer and attach it to the DOM
            if (Detector.webgl)
                renderer = new THREE.WebGLRenderer({
                    alpha: true,
                    antialias:true
                });
            else
                renderer = new THREE.CanvasRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);

            container.appendChild(renderer.domElement);

            document.addEventListener('mousedown', onMouseDown, false);
            document.addEventListener('mouseup', onMouseUp, false);
            document.addEventListener('mousemove', onMouseMove, false);

            render();
        });

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            material.uniforms["uResolution"].value = new THREE.Vector2(window.innerWidth, window.innerHeight);
        }

        function onMouseDown(e) {
            if (e.button === 0) {
                leftMouseButtonDown = true;
            }
            var vec4Mouse = material.uniforms["uMouse"].value;
            vec4Mouse.z = e.clientX;
            vec4Mouse.w = e.clientY;
        }

        function onMouseUp(e) {
            if (e.button === 0) {
                leftMouseButtonDown = false;
            } else {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.z = 0.0;
                vec4Mouse.w = 0.0;
            }
        }

        function onMouseMove(e) {
            if (leftMouseButtonDown === true) {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.x = e.clientX;
                vec4Mouse.y = e.clientY;
            }
        }

        function render() {
            material.uniforms["uGlobalTime"].value = clock.getElapsedTime();

            renderer.render(scene, camera);
            requestAnimationFrame(render);
        }
    </script>

</html>
