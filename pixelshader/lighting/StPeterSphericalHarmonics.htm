<html lang="en">
    <head>
        <title>WebGL/GLSL - St Peter's Spherical Harmonics Pixel Shader</title>
        <meta charset="utf-8">
        <link rel="stylesheet" type="text/css" href="../../css/styles.css">
    </head>

    <body>
        <div id="container"></div>
    </body>

    <script src="../../js/Three.min.js"></script>
    <script src="../../js/Detector.js"></script>

    <script type="x-shader/x-vertex" id="vertexShader">
        // Vertex Shader code

        void main() {
            gl_Position = vec4(position.xy, 1.0, 1.0);
        }
    </script>

    <script type="x-shader/x-fragment" id="fragmentShader">
        // Fragment Shader code

        uniform vec2 uResolution;
        uniform float uGlobalTime;
        uniform vec4 uMouse;
        uniform samplerCube uTexture0;

        // Lighting is done by Spherical Harmonics:
        // This one is a cheap variant presented in 2001 by Ravi Ramamoorthi
        // and Pat Hanrahan: http://graphics.stanford.edu/papers/envmap/
        // http://graphics.stanford.edu/papers/envmap/envmap.pdf
        // There's a C program (prefilter.c) provided to compute spherical harmonic
        // coefficients from light probe images (in the floating point format).
        // I used pvalue tool from Radiance package on my Ubuntu system to convert
        // angular light probe images in HDR format to floating point format with
        // the following command:
        // $ pvalue -df -H -h stpeters_probe.hdr > stpeters_probe.float
        // I then have slightly modified prefilter.c to output values with a factor
        // applied to have coefficients in a correct range (used a factor of 0.1),
        // and ran the following command:
        // $ ./prefilter stpeters_probe.float 1500
        // You can read too the Orange Book, chapter 12.3 (OpenGL Shading Language
        // by Randi J. Rost), it has been very useful.
        struct SHCoefficients {
            vec3 l00, l1m1, l10, l11, l2m2, l2m1, l20, l21, l22;
        };

        // These constants have been calculated with a light probe from this website:
        // http://www.pauldebevec.com/Probes/
        // The light probe image used is St. Peter's Basilica.
        const SHCoefficients stpeter = SHCoefficients(
            vec3( 0.3623915,  0.2624130,  0.2326261 ),
            vec3( 0.1759131,  0.1436266,  0.1260569 ),
            vec3(-0.0247311, -0.0101254, -0.0010745 ),
            vec3( 0.0346500,  0.0223184,  0.0101350 ),
            vec3( 0.0198140,  0.0144073,  0.0043987 ),
            vec3(-0.0469596, -0.0254485, -0.0117786 ),
            vec3(-0.0898667, -0.0760911, -0.0740964 ),
            vec3( 0.0050194,  0.0038841,  0.0001374 ),
            vec3(-0.0818750, -0.0321501,  0.0033399 )
        );

        vec3 calcIrradiance(vec3 nor, float sca) {
            const SHCoefficients c = stpeter;
            const float c1 = 0.429043;
            const float c2 = 0.511664;
            const float c3 = 0.743125;
            const float c4 = 0.886227;
            const float c5 = 0.247708;
            return (
                c1 * c.l22 * (nor.x * nor.x - nor.y * nor.y) +
                c3 * c.l20 * nor.z * nor.z +
                c4 * c.l00 -
                c5 * c.l20 +
                2.0 * c1 * c.l2m2 * nor.x * nor.y +
                2.0 * c1 * c.l21  * nor.x * nor.z +
                2.0 * c1 * c.l2m1 * nor.y * nor.z +
                2.0 * c2 * c.l11  * nor.x +
                2.0 * c2 * c.l1m1 * nor.y +
                2.0 * c2 * c.l10  * nor.z
            ) * sca;
        }

        vec3 spherePos = vec3(0.0, 1.0, 1.5);
        float sphereRadius = 2.5;

        float raytraceSphere(in vec3 ro, in vec3 rd, float tmin, float tmax, float r) {
            vec3 ce = ro - spherePos;
            float b = dot(rd, ce);
            float c = dot(ce, ce) - r * r;
            float t = b * b - c;
            if (t > tmin) {
                t = -b - sqrt(t);
                if (t < tmax)
                    return t;
                }
            return -1.0;
        }

        void main() {
            vec2 p = (2.0 * gl_FragCoord.xy - uResolution.xy) / uResolution.y;

            vec3 eye = vec3(0.0, 3.0, 5.0);
            vec2 rot = 6.2831 * (vec2(0.6 + uGlobalTime * 0.05, sin(uGlobalTime * 0.1) * 0.06) + vec2(1.0, 0.25) * (uMouse.xy - uResolution.xy * 0.25) / uResolution.x);
            eye.yz = cos(rot.y) * eye.yz + sin(rot.y) * eye.zy * vec2(-1.0, 1.0);
            eye.xz = cos(rot.x) * eye.xz + sin(rot.x) * eye.zx * vec2(1.0, -1.0);

            vec3 ro = eye;
            vec3 ta = vec3(0.0, 1.0, 0.0);

            vec3 cw = normalize(ta - ro);
            vec3 cu = normalize(cross(vec3(0.0, 1.0, 0.0), cw));
            vec3 cv = normalize(cross(cw, cu));
            mat3 cam = mat3(cu, cv, cw);

            vec3 rd = cam * normalize(vec3(p.xy, 1.0));

            vec3 col = textureCube(uTexture0, rd).xyz;

            float tmin = 0.1;
            float tmax = 50.0;

            // raytrace the sphere
            float tsph = raytraceSphere(ro, rd, tmin, tmax, sphereRadius);
            if (tsph > tmin) {
                vec3 spos = ro + rd * tsph;
                vec3 nor = normalize(spos - spherePos);
                float occ = 0.5 + 0.5 * nor.y;
                vec3 ref = reflect(rd, nor);
                vec3 refCol = pow(textureCube(uTexture0, ref).xyz, vec3(1.0));
                col = mix(refCol, calcIrradiance(nor, 2.25) * occ, 0.95);
            }

            gl_FragColor = vec4(col, 1.0);
        }
    </script>

    <script type="text/javascript" id="mainCode">
        var container,
            renderer,
            scene,
            mesh,
            camera,
            leftMouseButtonDown = false,
            clock = new THREE.Clock();

        window.addEventListener('resize', onWindowResize, false);
        window.addEventListener('load', function() {

            var cubeMapImage = new Image();
            cubeMapImage.src = "textures/cube02.png";

            function getCubeMapUrls() {
                // We use the following mapping scheme to reference the tiles in the source image:
                // Full cubemap tiles  xyz positions       Required tile sequence
                // [ 0] [ 4] [ 8]      [  ] [py] [  ]      [ ] [2] [ ]
                // [ 1] [ 5] [ 9]      [nx] [pz] [px]      [1] [4] [0]
                // [ 2] [ 6] [10]      [  ] [ny] [  ]      [ ] [3] [ ]
                // [ 3] [ 7] [11]      [  ] [nz] [  ]      [ ] [5] [ ]

                var cubeFaceIndices = [ 9, 1, 4, 6, 5, 7 ]; // xpos, xneg, ypos, yneg, zpos, zneg

                var cubeMapPieces = [];
                var textureWidth = cubeMapImage.width / 3;
                var textureHeight = cubeMapImage.height / 4;
                for(var x = 0; x < 3; x++) {
                    for(var y = 0; y < 4; y++) {
                        var canvas = document.createElement('canvas');
                        canvas.width  = textureWidth;
                        canvas.height = textureHeight;
                        var context2d = canvas.getContext('2d');
                        if (x == 1 && y == 3) { // flip zneg upside down
                            context2d.translate(textureWidth, textureHeight);
                            context2d.rotate(Math.PI);
                        }
                        context2d.drawImage(cubeMapImage, x * textureWidth, y * textureHeight, textureWidth, textureHeight, 0, 0, canvas.width, canvas.height);

                        cubeMapPieces.push(canvas.toDataURL());
                    }
                }
                var urls = [];
                for (var i = 0; i < 6; i++) { // select the right tiles for the 6 different faces of the cubemap
                    urls.push(cubeMapPieces[cubeFaceIndices[i]]);
                }
                return urls;
            }

            // grab the container from the DOM
            container = document.getElementById("container");

            // create a scene
            scene = new THREE.Scene();

            // create a camera the size of the browser window
            camera = new THREE.PerspectiveCamera(
                90,
                window.innerWidth / window.innerHeight,
                1,
                10000);
            camera.position.z = 200;

            // add the camera to the scene
            scene.add(camera);

            // create a shader material
            material = new THREE.ShaderMaterial({
                uniforms: {
                    uResolution: { type:"v2", value: new THREE.Vector2(window.innerWidth, window.innerHeight) },
                    uGlobalTime: { type:"f", value: 1.0 },
                    uMouse: { type:"v4", value: new THREE.Vector4(0, 0, 0, 0) },
                    uTexture0: { type: "t", value: THREE.ImageUtils.loadTextureCube(getCubeMapUrls()) }
                },
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent,
                depthTest: false
            });

            // create a plane mesh and assign the material, then add the mesh to the scene (fullscreen quad)
            mesh = new THREE.Mesh(
                new THREE.PlaneBufferGeometry(2, 2),
                material
            );
            scene.add(mesh);

            // create the renderer and attach it to the DOM
            if (Detector.webgl)
                renderer = new THREE.WebGLRenderer({
                    alpha: true,
                    antialias:true
                });
            else
                renderer = new THREE.CanvasRenderer();
            renderer.setSize(window.innerWidth, window.innerHeight);

            container.appendChild(renderer.domElement);

            document.addEventListener('mousedown', onMouseDown, false);
            document.addEventListener('mouseup', onMouseUp, false);
            document.addEventListener('mousemove', onMouseMove, false);

            render();
        });

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
            material.uniforms["uResolution"].value = new THREE.Vector2(window.innerWidth, window.innerHeight);
        }

        function onMouseDown(e) {
            if (e.button === 0) {
                leftMouseButtonDown = true;
            }
            var vec4Mouse = material.uniforms["uMouse"].value;
            vec4Mouse.z = e.clientX;
            vec4Mouse.w = e.clientY;
        }

        function onMouseUp(e) {
            if (e.button === 0) {
                leftMouseButtonDown = false;
            } else {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.z = 0.0;
                vec4Mouse.w = 0.0;
            }
        }

        function onMouseMove(e) {
            if (leftMouseButtonDown === true) {
                var vec4Mouse = material.uniforms["uMouse"].value;
                vec4Mouse.x = e.clientX;
                vec4Mouse.y = e.clientY;
            }
        }

        function render() {
            material.uniforms["uGlobalTime"].value = clock.getElapsedTime();

            renderer.render(scene, camera);
            requestAnimationFrame(render);
        }
    </script>

</html>
